{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from string import digits\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'test', 'train', 'validation']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"plant_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Archive:  ind-eng.zip',\n",
       " 'replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL',\n",
       " '(EOF or read error, treating as \"[N]one\" ...)']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!curl -O http://www.manythings.org/anki/ind-eng.zip\n",
    "!!unzip ind-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 8471  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = \"ind.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Lari!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Siapa?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Wow!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>Tolong!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump!</td>\n",
       "      <td>Lompat!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465</th>\n",
       "      <td>Every student who has graduated from our unive...</td>\n",
       "      <td>Semua mahasiswa yang telah menyelesaikan studi...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>If you don't want to put on sunscreen, that's ...</td>\n",
       "      <td>Kalau kamu tidak mau pakai tabir surya, ya, te...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8467</th>\n",
       "      <td>When she was finished ironing, Mary switched o...</td>\n",
       "      <td>Ketika dia sudah selesai menyetrika, Mary mema...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8468</th>\n",
       "      <td>Irene Pepperberg, a researcher at Northwestern...</td>\n",
       "      <td>Irene Pepperberg, seorang peneliti di Universi...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8469</th>\n",
       "      <td>If a person has not had a chance to acquire hi...</td>\n",
       "      <td>Jika seseorang tidak berkesempatan untuk mengu...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8470 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "0                                                  Run!   \n",
       "1                                                  Who?   \n",
       "2                                                  Wow!   \n",
       "3                                                 Help!   \n",
       "4                                                 Jump!   \n",
       "...                                                 ...   \n",
       "8465  Every student who has graduated from our unive...   \n",
       "8466  If you don't want to put on sunscreen, that's ...   \n",
       "8467  When she was finished ironing, Mary switched o...   \n",
       "8468  Irene Pepperberg, a researcher at Northwestern...   \n",
       "8469  If a person has not had a chance to acquire hi...   \n",
       "\n",
       "                                                 target  \\\n",
       "0                                                 Lari!   \n",
       "1                                                Siapa?   \n",
       "2                                                  Wow!   \n",
       "3                                               Tolong!   \n",
       "4                                               Lompat!   \n",
       "...                                                 ...   \n",
       "8465  Semua mahasiswa yang telah menyelesaikan studi...   \n",
       "8466  Kalau kamu tidak mau pakai tabir surya, ya, te...   \n",
       "8467  Ketika dia sudah selesai menyetrika, Mary mema...   \n",
       "8468  Irene Pepperberg, seorang peneliti di Universi...   \n",
       "8469  Jika seseorang tidak berkesempatan untuk mengu...   \n",
       "\n",
       "                                               comments  \n",
       "0     CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "1     CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "2     CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "3     CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "4     CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "...                                                 ...  \n",
       "8465  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "8466  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "8467  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "8468  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "8469  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "\n",
       "[8470 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table(data_path , names=['source','target','comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    num_digits= str.maketrans('','', digits)\n",
    "    \n",
    "    sentence= sentence.lower()\n",
    "    sentence= re.sub(\" +\", \" \", sentence)\n",
    "    sentence= re.sub(\"'\", '', sentence)\n",
    "    sentence= sentence.translate(num_digits)\n",
    "    sentence= re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.rstrip().strip()\n",
    "    sentence=  'start_ ' + sentence + ' _end'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_ can you do it in thirty minutes ? _end\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_sentence(\"Can you do it in thirty minutes?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "      \n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "  \n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "  return zip(*word_pairs)\n",
    "sample_size=8470\n",
    "source, target, comment= create_dataset(data_path, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split(\"\\t\")\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "# \n",
    "print(max_encoder_seq_length)\n",
    "# print(\"Number of samples:\", len(input_texts))\n",
    "# print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "# print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "# print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "# print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "# \n",
    "# input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "# target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "# \n",
    "# encoder_input_data = np.zeros(\n",
    "#     (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    "# )\n",
    "# decoder_input_data = np.zeros(\n",
    "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    "# )\n",
    "# decoder_target_data = np.zeros(\n",
    "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    "# )\n",
    "# \n",
    "# for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "#     for t, char in enumerate(input_text):\n",
    "#         encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "#     encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "#     for t, char in enumerate(target_text):\n",
    "#         # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "#         decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "#         if t > 0:\n",
    "#             # decoder_target_data will be ahead by one timestep\n",
    "#             # and will not include the start character.\n",
    "#             decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "#     decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19576357cadf29002c6035c96afd834283ceb1b7cc505aa7c31730dd79d5f4e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('deeplearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
